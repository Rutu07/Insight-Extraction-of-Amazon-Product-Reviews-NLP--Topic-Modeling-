{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ff11a75c92a843edb58db103fbab14cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_91df64d1fdaa4cba9926e7e9cb3c35e7",
              "IPY_MODEL_a7b094dd88714f28bdb733769bb75d14",
              "IPY_MODEL_1e0cda41124a47c1a5a6c954153d6fff"
            ],
            "layout": "IPY_MODEL_c8a72ad78b354299b6b8072aabf13a16"
          }
        },
        "91df64d1fdaa4cba9926e7e9cb3c35e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3f31bc3fe8ab4c3f9f0f0e35e435c896",
            "placeholder": "​",
            "style": "IPY_MODEL_642d00bf3155440e87fe6d480c66b889",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "a7b094dd88714f28bdb733769bb75d14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5cdaa88ea1a744f685afec7645c12ee3",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d630a95ecf674b1db145295ad4dc6f6c",
            "value": 570
          }
        },
        "1e0cda41124a47c1a5a6c954153d6fff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a87765ed57d84c66a7e9f4ea2680f2b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b394f3ff62234cdd87d7f896bf32513e",
            "value": " 570/570 [00:00&lt;00:00, 17.1kB/s]"
          }
        },
        "c8a72ad78b354299b6b8072aabf13a16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f31bc3fe8ab4c3f9f0f0e35e435c896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "642d00bf3155440e87fe6d480c66b889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5cdaa88ea1a744f685afec7645c12ee3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d630a95ecf674b1db145295ad4dc6f6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a87765ed57d84c66a7e9f4ea2680f2b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b394f3ff62234cdd87d7f896bf32513e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bc3149d3050e4595bfdd5ac5d28ee1e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c0539de00c5045e392c347328710cf23",
              "IPY_MODEL_649368ecdd0943b0b06ee2b5fa89b6e8",
              "IPY_MODEL_f85d9bce7ee54e08b95058834d0b284d"
            ],
            "layout": "IPY_MODEL_2e24660a6c2b4b02a1abb01b1724fe41"
          }
        },
        "c0539de00c5045e392c347328710cf23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ed2c8b5a19b49b08767b0d8c5a53e5f",
            "placeholder": "​",
            "style": "IPY_MODEL_8bd452f93a22432d81a189ed1a623102",
            "value": "Downloading (…)&quot;pytorch_model.bin&quot;;: 100%"
          }
        },
        "649368ecdd0943b0b06ee2b5fa89b6e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e289262544a34713ade2575c0bd1ce70",
            "max": 440473133,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d6d93af74fa74087a3a9b2511df25b57",
            "value": 440473133
          }
        },
        "f85d9bce7ee54e08b95058834d0b284d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b7e15a74941494ab1059e025fc9265a",
            "placeholder": "​",
            "style": "IPY_MODEL_6c1719e199d741e4b387d46f46b79e64",
            "value": " 440M/440M [00:02&lt;00:00, 191MB/s]"
          }
        },
        "2e24660a6c2b4b02a1abb01b1724fe41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ed2c8b5a19b49b08767b0d8c5a53e5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8bd452f93a22432d81a189ed1a623102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e289262544a34713ade2575c0bd1ce70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6d93af74fa74087a3a9b2511df25b57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b7e15a74941494ab1059e025fc9265a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1719e199d741e4b387d46f46b79e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c39f978012b546cf9b286348603e8d72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d9e26b446b874cc989414d9cbf838a6a",
              "IPY_MODEL_40c0dae8bed9420f938fecf7410084f9",
              "IPY_MODEL_09cde026ae5e4995bdeb2e7baadde615"
            ],
            "layout": "IPY_MODEL_e03e21246c1e4c2c9909a23b83a25305"
          }
        },
        "d9e26b446b874cc989414d9cbf838a6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23130f3e04f24f91b73b7dc141d0a0f5",
            "placeholder": "​",
            "style": "IPY_MODEL_537ea44768af4514bd439858608de419",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "40c0dae8bed9420f938fecf7410084f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_556d34f330d5463680335c6df8016f0c",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_77a97ed7a1544e4e9c2acb743e654bbf",
            "value": 28
          }
        },
        "09cde026ae5e4995bdeb2e7baadde615": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20b057913ccb4e9fa9df348d4abc7998",
            "placeholder": "​",
            "style": "IPY_MODEL_c7fd93dc27b840dca17a7d6c32ac1e12",
            "value": " 28.0/28.0 [00:00&lt;00:00, 1.43kB/s]"
          }
        },
        "e03e21246c1e4c2c9909a23b83a25305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23130f3e04f24f91b73b7dc141d0a0f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "537ea44768af4514bd439858608de419": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "556d34f330d5463680335c6df8016f0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77a97ed7a1544e4e9c2acb743e654bbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20b057913ccb4e9fa9df348d4abc7998": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c7fd93dc27b840dca17a7d6c32ac1e12": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb24f773157649b3a4f7e50109220a0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725f9a15af1647fd955ded9a197030e6",
              "IPY_MODEL_e6dc50691c19454db2ca0ab878d2fd19",
              "IPY_MODEL_2c7bef8d36444120b4d35bc03881e755"
            ],
            "layout": "IPY_MODEL_8fea4c29a75b4e1db1ac1b3bee90966b"
          }
        },
        "725f9a15af1647fd955ded9a197030e6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e483f3f0d854fbe90d8e8516b284d08",
            "placeholder": "​",
            "style": "IPY_MODEL_afdf3a2085534cacbcc7da6a7eb04d23",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "e6dc50691c19454db2ca0ab878d2fd19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_944bcef05ced45a0947e2c9dc302ad60",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7b6801e647744441bf63e08bce887c33",
            "value": 231508
          }
        },
        "2c7bef8d36444120b4d35bc03881e755": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7fc82a70d79413aac5842c1778eacbb",
            "placeholder": "​",
            "style": "IPY_MODEL_28b1d24b5a184accbbd313063b5f5a55",
            "value": " 232k/232k [00:00&lt;00:00, 2.18MB/s]"
          }
        },
        "8fea4c29a75b4e1db1ac1b3bee90966b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e483f3f0d854fbe90d8e8516b284d08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "afdf3a2085534cacbcc7da6a7eb04d23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "944bcef05ced45a0947e2c9dc302ad60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7b6801e647744441bf63e08bce887c33": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7fc82a70d79413aac5842c1778eacbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28b1d24b5a184accbbd313063b5f5a55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1024cbd7ae1f477b98dc47125bb08869": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d050a99715e8412ab585d726b5798e4e",
              "IPY_MODEL_94e659c43387473b89a9f872b49b5a53",
              "IPY_MODEL_7e8d760330f54455b0720d64edc15c15"
            ],
            "layout": "IPY_MODEL_25695492e3354225bfacee1d9198bfe9"
          }
        },
        "d050a99715e8412ab585d726b5798e4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b10cb4e27c954ed2829bb5af97ed1e1d",
            "placeholder": "​",
            "style": "IPY_MODEL_2a4cc6537702414fae4e6002a7ddc8fc",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "94e659c43387473b89a9f872b49b5a53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f3ae7403bc2145cfa479c3d2904240d4",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a8a34207d5694bccbda468ec906b4740",
            "value": 466062
          }
        },
        "7e8d760330f54455b0720d64edc15c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_67a97e4a49114575bb0f1c1521153005",
            "placeholder": "​",
            "style": "IPY_MODEL_fbdc5fc7e3c74f1ca96cb7fa221bc777",
            "value": " 466k/466k [00:00&lt;00:00, 3.43MB/s]"
          }
        },
        "25695492e3354225bfacee1d9198bfe9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b10cb4e27c954ed2829bb5af97ed1e1d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a4cc6537702414fae4e6002a7ddc8fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f3ae7403bc2145cfa479c3d2904240d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a8a34207d5694bccbda468ec906b4740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "67a97e4a49114575bb0f1c1521153005": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fbdc5fc7e3c74f1ca96cb7fa221bc777": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "166aa737ed6d413db23fca3e308e2f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3176e8b37ce243969707a8c6e51967ce",
              "IPY_MODEL_c4ec754975b048a1853e1b326e4f70d7",
              "IPY_MODEL_bfe44a30a477436d9205cf1b6a6e0176"
            ],
            "layout": "IPY_MODEL_43c86486da9143a49632e89b8811185d"
          }
        },
        "3176e8b37ce243969707a8c6e51967ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8063cb2b012d4e12b778b22a5cf09a70",
            "placeholder": "​",
            "style": "IPY_MODEL_f59934faf4524c77bd55f88d246cf4fe",
            "value": "100%"
          }
        },
        "c4ec754975b048a1853e1b326e4f70d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bafada90012e47c390d968641b9f0016",
            "max": 19999,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a1937a07ee294aa38bcc70318b4cc8fd",
            "value": 19999
          }
        },
        "bfe44a30a477436d9205cf1b6a6e0176": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8afd0f9cafcb40809897800c8e10e0c0",
            "placeholder": "​",
            "style": "IPY_MODEL_d197fdf960404d39a4883d599d3afe46",
            "value": " 19999/19999 [00:11&lt;00:00, 1979.21it/s]"
          }
        },
        "43c86486da9143a49632e89b8811185d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8063cb2b012d4e12b778b22a5cf09a70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f59934faf4524c77bd55f88d246cf4fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bafada90012e47c390d968641b9f0016": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1937a07ee294aa38bcc70318b4cc8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8afd0f9cafcb40809897800c8e10e0c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d197fdf960404d39a4883d599d3afe46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rutu07/Insight-Extraction-of-Amazon-Product-Reviews-NLP--Topic-Modeling-/blob/main/Sentiment_Analysis_of_Amazon_Product_Reviews_using_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i6e_CLkpoTUr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d1Aq1koswNtu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- GPU (Graphics Processing Unit) enable paralle processing of complex tasks. Lot of computing power is required to train Neural Networks on thousands/millions of records and GPUs provide this computing power. \n",
        "- Traditional CPUs are capable of completing task in sequential manner along with their multi-cores, however GPUs process many parts of data simultaneously."
      ],
      "metadata": {
        "id": "6Rg9VU3HwOVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "from sklearn.model_selection import train_test_split\n",
        "pd.set_option('display.max_colwidth',200)\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#library for progress bar\n",
        "from tqdm import notebook\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "# importing nn module\n",
        "import torch.nn as nn\n",
        "\n",
        "#library for computing class weights\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from google.colab import drive"
      ],
      "metadata": {
        "id": "qZYw3GFgvHyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QMazwWryxoC0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Runtime->Change RunTIme-> Select GPU in Hardware Accelrator\n"
      ],
      "metadata": {
        "id": "cWsFU4NBxoXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking if GPU is available. \n",
        "if torch.cuda.is_available():\n",
        "  device=torch.device('cuda')"
      ],
      "metadata": {
        "id": "0_k00AxdxiKo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(device)\n",
        "torch.cuda.get_device_name(0)\n",
        "# Current GPU is Tesla T4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oXQhWDNtvIO3",
        "outputId": "4f3f57d1-ae74-4c90-8e59-acb7e0ccdaf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yqVBhDYCyOro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 2: Installing Hugging Face's Transformers Library\n",
        "- Hugging face is one of the most popular NLP library and provides a wide range of transformer-based models such as BERT, GPT-2, Roberta, and so on.\n"
      ],
      "metadata": {
        "id": "02SHj9i2yPSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "PpbMWwkgvIs0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8c8a115-9a56-4dd0-d0a9-a48108ccb6a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting transformers\n",
            "  Downloading transformers-4.26.1-py3-none-any.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m34.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tokenizers!=0.11.3,<0.14,>=0.11.1\n",
            "  Downloading tokenizers-0.13.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from transformers) (23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.8/dist-packages (from transformers) (4.64.1)\n",
            "Collecting huggingface-hub<1.0,>=0.11.0\n",
            "  Downloading huggingface_hub-0.12.1-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from transformers) (2.25.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (4.0.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->transformers) (1.24.3)\n",
            "Installing collected packages: tokenizers, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.12.1 tokenizers-0.13.2 transformers-4.26.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLTf0t1Y1gQ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 3: Installing BertModel "
      ],
      "metadata": {
        "id": "mKSoA0la14_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- BERT uncased: This model was trained on lower case text data. Other types of pre-trained models, can be found at https://huggingface.co/models\n"
      ],
      "metadata": {
        "id": "MpFqUGlO0GBw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.modeling_bert import BertModel\n",
        "# Import BERT pretrained module\n",
        "from transformers import BertModel\n",
        "\n",
        "#Download uncased bert base model\n",
        "bert=BertModel.from_pretrained('bert-base-uncased')"
      ],
      "metadata": {
        "id": "VLtv1XgKvI3z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153,
          "referenced_widgets": [
            "ff11a75c92a843edb58db103fbab14cf",
            "91df64d1fdaa4cba9926e7e9cb3c35e7",
            "a7b094dd88714f28bdb733769bb75d14",
            "1e0cda41124a47c1a5a6c954153d6fff",
            "c8a72ad78b354299b6b8072aabf13a16",
            "3f31bc3fe8ab4c3f9f0f0e35e435c896",
            "642d00bf3155440e87fe6d480c66b889",
            "5cdaa88ea1a744f685afec7645c12ee3",
            "d630a95ecf674b1db145295ad4dc6f6c",
            "a87765ed57d84c66a7e9f4ea2680f2b0",
            "b394f3ff62234cdd87d7f896bf32513e",
            "bc3149d3050e4595bfdd5ac5d28ee1e2",
            "c0539de00c5045e392c347328710cf23",
            "649368ecdd0943b0b06ee2b5fa89b6e8",
            "f85d9bce7ee54e08b95058834d0b284d",
            "2e24660a6c2b4b02a1abb01b1724fe41",
            "3ed2c8b5a19b49b08767b0d8c5a53e5f",
            "8bd452f93a22432d81a189ed1a623102",
            "e289262544a34713ade2575c0bd1ce70",
            "d6d93af74fa74087a3a9b2511df25b57",
            "2b7e15a74941494ab1059e025fc9265a",
            "6c1719e199d741e4b387d46f46b79e64"
          ]
        },
        "outputId": "d6b1c907-f8c5-4b00-a596-81c176f003d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff11a75c92a843edb58db103fbab14cf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)\"pytorch_model.bin\";:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "bc3149d3050e4595bfdd5ac5d28ee1e2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print BERT arcitecture\n",
        "print(bert)"
      ],
      "metadata": {
        "id": "r3isN0Fr01bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05ff5447-0212-4872-f5bd-44e8676d4d3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BertModel(\n",
            "  (embeddings): BertEmbeddings(\n",
            "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
            "    (position_embeddings): Embedding(512, 768)\n",
            "    (token_type_embeddings): Embedding(2, 768)\n",
            "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "    (dropout): Dropout(p=0.1, inplace=False)\n",
            "  )\n",
            "  (encoder): BertEncoder(\n",
            "    (layer): ModuleList(\n",
            "      (0): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (1): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (2): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (3): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (4): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (5): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (6): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (7): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (8): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (9): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (10): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "      (11): BertLayer(\n",
            "        (attention): BertAttention(\n",
            "          (self): BertSelfAttention(\n",
            "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "          (output): BertSelfOutput(\n",
            "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "            (dropout): Dropout(p=0.1, inplace=False)\n",
            "          )\n",
            "        )\n",
            "        (intermediate): BertIntermediate(\n",
            "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
            "          (intermediate_act_fn): GELUActivation()\n",
            "        )\n",
            "        (output): BertOutput(\n",
            "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
            "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (pooler): BertPooler(\n",
            "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
            "    (activation): Tanh()\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 4: Importing BERT tokenizer\n",
        "It tencodes text into positional encodings combined with word(contextual) embeddings. The tokenizer version present in transformers library is the fast version."
      ],
      "metadata": {
        "id": "XiccmS2N2BAF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.models.bert.tokenization_bert_fast import BertTokenizerFast\n",
        "# importing BERT tokenizer \n",
        "tokenizer=BertTokenizerFast.from_pretrained('bert-base-uncased',do_lower_case=True)\n"
      ],
      "metadata": {
        "id": "lcel2F6Q1Dk_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 113,
          "referenced_widgets": [
            "c39f978012b546cf9b286348603e8d72",
            "d9e26b446b874cc989414d9cbf838a6a",
            "40c0dae8bed9420f938fecf7410084f9",
            "09cde026ae5e4995bdeb2e7baadde615",
            "e03e21246c1e4c2c9909a23b83a25305",
            "23130f3e04f24f91b73b7dc141d0a0f5",
            "537ea44768af4514bd439858608de419",
            "556d34f330d5463680335c6df8016f0c",
            "77a97ed7a1544e4e9c2acb743e654bbf",
            "20b057913ccb4e9fa9df348d4abc7998",
            "c7fd93dc27b840dca17a7d6c32ac1e12",
            "eb24f773157649b3a4f7e50109220a0e",
            "725f9a15af1647fd955ded9a197030e6",
            "e6dc50691c19454db2ca0ab878d2fd19",
            "2c7bef8d36444120b4d35bc03881e755",
            "8fea4c29a75b4e1db1ac1b3bee90966b",
            "6e483f3f0d854fbe90d8e8516b284d08",
            "afdf3a2085534cacbcc7da6a7eb04d23",
            "944bcef05ced45a0947e2c9dc302ad60",
            "7b6801e647744441bf63e08bce887c33",
            "b7fc82a70d79413aac5842c1778eacbb",
            "28b1d24b5a184accbbd313063b5f5a55",
            "1024cbd7ae1f477b98dc47125bb08869",
            "d050a99715e8412ab585d726b5798e4e",
            "94e659c43387473b89a9f872b49b5a53",
            "7e8d760330f54455b0720d64edc15c15",
            "25695492e3354225bfacee1d9198bfe9",
            "b10cb4e27c954ed2829bb5af97ed1e1d",
            "2a4cc6537702414fae4e6002a7ddc8fc",
            "f3ae7403bc2145cfa479c3d2904240d4",
            "a8a34207d5694bccbda468ec906b4740",
            "67a97e4a49114575bb0f1c1521153005",
            "fbdc5fc7e3c74f1ca96cb7fa221bc777"
          ]
        },
        "outputId": "81650c31-8e16-4843-af4a-6793c98722cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c39f978012b546cf9b286348603e8d72"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb24f773157649b3a4f7e50109220a0e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1024cbd7ae1f477b98dc47125bb08869"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Steps occuring in Input Encoding**\n",
        "\n",
        "1. Tokenization\n",
        "2. Special Tokens\n",
        "  * Prepending [CLS] token at the start of the sequence\n",
        "  * Appneding [SEP] token at the end of the seqence\n",
        "3. Pad sequences\n",
        "4. Convert tokens into integers(vector embeddings)\n",
        "5. Create attention masks to indicate non padded elements.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "KPYFKIN-7o7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text='Jim Henson was a puppeteer'\n",
        "sentence_id=tokenizer.encode(text,\n",
        "                             # add special character tokens\n",
        "                             add_special_tokens=True,\n",
        "                             # Specifying maximum length for any input sequences\n",
        "                             max_length=10,\n",
        "                             # if exceeeding 10, then it will be truncated, if <10, then it will be padded.\n",
        "                             truncation=True,\n",
        "                             # add pad tokens to the right side of the sequence\n",
        "                             pad_to_max_length='right'\n",
        "                             )\n",
        "print(\"Integer Sequence:{}\".format(sentence_id))"
      ],
      "metadata": {
        "id": "tK0Tes6Z1D5V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258d8689-961d-460b-902b-e38ac392db1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Integer Sequence:[101, 3958, 27227, 2001, 1037, 13997, 11510, 102, 0, 0]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- [CLS] is represented by 101 where as [SEP] is represented by 102. Two zeros at the end represent padded elements to have a seuqnce of length 10."
      ],
      "metadata": {
        "id": "6QrcKfrx9v1b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# converting integers back to text\n",
        "print(\"Tokenizer Text: \",tokenizer.convert_ids_to_tokens(sentence_id))"
      ],
      "metadata": {
        "id": "Tn5Zok3N1ESU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ec2c6a8-3e4f-4ac0-aba0-566dd965db84"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokenizer Text:  ['[CLS]', 'jim', 'henson', 'was', 'a', 'puppet', '##eer', '[SEP]', '[PAD]', '[PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note that puppeteer was not a part of Bert tokenizer vocabulary while training. It doesn't have any word embedding for word puppeteer. Hence it was split into known part 'puppet' and unknown part '##eer'. The tokenizer has embeddings for both the tokens. ## represents that the token is a sub word. This is how BERT tokenizer handles unkwown words.\n",
        "\n",
        "- Using tokenizer.decode(), this can be decoded back into original sentence"
      ],
      "metadata": {
        "id": "T5IwrfCt-LLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoded=tokenizer.decode(sentence_id)\n",
        "print('Decoded String:{}'.format(decoded))"
      ],
      "metadata": {
        "id": "fE5R93bd1Ed-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b30ce8-bfa2-4813-b77c-e9966fdb54cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decoded String:[CLS] jim henson was a puppeteer [SEP] [PAD] [PAD]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Masking needs to be done to avoid performing attention on padding token indices.\n",
        "- mask value=1 for tokens and 0 for unmasked tokens"
      ],
      "metadata": {
        "id": "9Uws_ULn_OGo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "att_mask=[int(tok>0) for tok in sentence_id]\n",
        "print(att_mask)"
      ],
      "metadata": {
        "id": "azy7xAEC_LoF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e16f3cc-9b2b-4f9d-c604-856d822fca1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Understanding Input and Output of BERT Tokenizer**\n"
      ],
      "metadata": {
        "id": "tI12evHX_zhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- To understand unsqueeze() and squeeze() function: https://stackoverflow.com/questions/57237352/what-does-unsqueeze-do-in-pytorch\n"
      ],
      "metadata": {
        "id": "WseHlEeXCuLd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert lists to tensors\n",
        "# torch.tensor creates a tensor of given data\n",
        "sent_id=torch.tensor(sentence_id)\n",
        "attn_mask=torch.tensor(att_mask)\n",
        "print('Shape of sentence_id before reshaping is: {}'.format(sent_id.shape))\n",
        "print('Shape of sentence_id before reshaping is: {}'.format(attn_mask.shape))\n",
        "print('\\n')\n",
        "# reshaping tensor in form of batch,text length\n",
        "sent_id=sent_id.unsqueeze(0)\n",
        "attn_mask=attn_mask.unsqueeze(0)\n",
        "print('Shape of sentence_id after reshaping is: {}'.format(sent_id.shape))\n",
        "print('Shape of sentence_id after reshaping is: {}'.format(attn_mask.shape))\n",
        "print('\\n')\n",
        "# reshaped tensor\n",
        "print(sent_id)\n"
      ],
      "metadata": {
        "id": "3-I52Khv_6jX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "617dfd00-ec57-4fea-a8ec-4271c747952b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of sentence_id before reshaping is: torch.Size([10])\n",
            "Shape of sentence_id before reshaping is: torch.Size([10])\n",
            "\n",
            "\n",
            "Shape of sentence_id after reshaping is: torch.Size([1, 10])\n",
            "Shape of sentence_id after reshaping is: torch.Size([1, 10])\n",
            "\n",
            "\n",
            "tensor([[  101,  3958, 27227,  2001,  1037, 13997, 11510,   102,     0,     0]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Here we can see that list of integers has beem converted into pytorch tensor of dimension (1,10)"
      ],
      "metadata": {
        "id": "M1yRfLXRDzAS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# passing integer sequence and attention mask tensor to BERT model\n",
        "outputs=bert(sent_id,attention_mask=attn_mask)\n"
      ],
      "metadata": {
        "id": "nHMUs9atBm-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unpacking the output of BERT model\n",
        "\n",
        "# all_hidden_states is a collection of all the output vectors/ hidden states (of encoder) at each timestamps or position of the BERT model\n",
        "all_hidden_states=outputs[0]\n",
        "\n",
        "print(all_hidden_states.shape)\n",
        "print(all_hidden_states)"
      ],
      "metadata": {
        "id": "9gjJ-7X4BnO6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef98435b-b491-4dcc-f24f-b72c1130d9b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 768])\n",
            "tensor([[[-0.2531,  0.2038, -0.3862,  ..., -0.3034,  0.6197,  0.2373],\n",
            "         [-0.2323, -0.0044, -0.5479,  ...,  0.0765,  0.8122, -0.4710],\n",
            "         [ 0.2590,  0.7140, -0.5438,  ..., -0.3774,  0.9987,  0.5400],\n",
            "         ...,\n",
            "         [ 0.7873,  0.3299, -0.0351,  ...,  0.2932, -0.5141,  0.0308],\n",
            "         [-0.5547, -0.3669, -0.1106,  ...,  0.2593,  0.5321, -0.3871],\n",
            "         [-0.5461, -0.2414, -0.2111,  ...,  0.3100,  0.5863, -0.3467]]],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 1 because we have only one senetence(sequence)\n",
        "- 10 because we have maximum of 10 words in each sequence. For shorter sentences, 0 are padded at right side.\n",
        "- 768 is the default dim of BERT output vector where every word out of 10 words is represented into a vector of 768 columns"
      ],
      "metadata": {
        "id": "yQccq9DOEe22"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# this output contains output vector against the CLS token only (at the first position of BERT model)\n",
        "# this output vector encodes the entire input sequence \n",
        "\n",
        "cls_hidden_state=outputs[1]\n",
        " \n",
        "print(cls_hidden_state.shape)\n",
        "print(cls_hidden_state)"
      ],
      "metadata": {
        "id": "-x7ck6KSEc19",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3744498-5a4a-427f-f3f7-322857c0bd64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 768])\n",
            "tensor([[-0.8767, -0.4109, -0.1220,  0.4494,  0.1945, -0.2698,  0.8316,  0.3127,\n",
            "          0.1178, -1.0000, -0.1561,  0.6677,  0.9891, -0.3451,  0.8812, -0.6753,\n",
            "         -0.3079, -0.5580,  0.4380, -0.4588,  0.5831,  0.9956,  0.4467,  0.2863,\n",
            "          0.3924,  0.6864, -0.7513,  0.9043,  0.9436,  0.8207, -0.6493,  0.3524,\n",
            "         -0.9919, -0.2295, -0.0742, -0.9936,  0.3698, -0.7558,  0.0792, -0.2218,\n",
            "         -0.8637,  0.4711,  0.9997, -0.4368,  0.0404, -0.3498, -1.0000,  0.2663,\n",
            "         -0.8711,  0.0508,  0.0505, -0.1634,  0.1716,  0.4363,  0.4330, -0.0333,\n",
            "         -0.0416,  0.2206, -0.2568, -0.6122, -0.5916,  0.2569, -0.2622, -0.9041,\n",
            "          0.3221, -0.2394, -0.2634, -0.3454, -0.0723,  0.0081,  0.8297,  0.2279,\n",
            "          0.1614, -0.6555, -0.2062,  0.3280, -0.4016,  1.0000, -0.0952, -0.9874,\n",
            "         -0.0400,  0.0717,  0.3675,  0.3373, -0.3710, -1.0000,  0.4479, -0.1722,\n",
            "         -0.9917,  0.2677,  0.4844, -0.2207, -0.3207,  0.3715, -0.2171, -0.2522,\n",
            "         -0.3071, -0.3161, -0.1988, -0.0860, -0.0114, -0.1982, -0.1799, -0.3221,\n",
            "          0.1751, -0.4442, -0.1570, -0.0434, -0.0893,  0.5717,  0.3112, -0.2900,\n",
            "          0.3305, -0.9430,  0.6061, -0.2984, -0.9873, -0.3956, -0.9926,  0.7857,\n",
            "         -0.1692, -0.2719,  0.9505,  0.5628,  0.2904, -0.1693,  0.1619, -1.0000,\n",
            "         -0.1697, -0.1534,  0.2513, -0.2857, -0.9846, -0.9638,  0.5565,  0.9200,\n",
            "          0.1805,  0.9995, -0.2122,  0.9391,  0.3246, -0.3937, -0.1248, -0.5209,\n",
            "          0.0519,  0.1141, -0.6463,  0.3529, -0.0322, -0.3837, -0.3796, -0.2830,\n",
            "          0.1280, -0.9191, -0.4201,  0.9145,  0.0713, -0.2455,  0.5212, -0.2642,\n",
            "         -0.3675,  0.8082,  0.2577,  0.2755, -0.0157,  0.3675, -0.3107,  0.4502,\n",
            "         -0.8224,  0.2841,  0.4360, -0.3193,  0.2164, -0.9851, -0.4444,  0.5759,\n",
            "          0.9878,  0.7531,  0.3384,  0.2003, -0.2602,  0.4695, -0.9561,  0.9855,\n",
            "         -0.1712,  0.2295,  0.1220, -0.1386, -0.8436, -0.3783,  0.8371, -0.3204,\n",
            "         -0.8457, -0.0473, -0.4219, -0.3593, -0.2187,  0.5282, -0.3149, -0.4375,\n",
            "         -0.0440,  0.9242,  0.9296,  0.7735, -0.3733,  0.3945, -0.9049, -0.2898,\n",
            "          0.2695,  0.2910,  0.1695,  0.9932, -0.3069, -0.1611, -0.8349, -0.9827,\n",
            "          0.1299, -0.8555, -0.0531, -0.6830,  0.3926,  0.2873, -0.1899,  0.2598,\n",
            "         -0.9201, -0.7455,  0.3943, -0.3955,  0.4015, -0.2341,  0.7593,  0.3421,\n",
            "         -0.6143,  0.5170,  0.8987,  0.1072, -0.6858,  0.6481, -0.2454,  0.8712,\n",
            "         -0.5958,  0.9936,  0.3404,  0.4972, -0.9452, -0.2347, -0.8748, -0.0154,\n",
            "         -0.1293, -0.5265,  0.4235,  0.4206,  0.3663,  0.7488, -0.4650,  0.9900,\n",
            "         -0.8695, -0.9701, -0.5203, -0.0900, -0.9914,  0.0978,  0.2844, -0.0424,\n",
            "         -0.4649, -0.4546, -0.9620,  0.8035,  0.2177,  0.9705, -0.0793, -0.7985,\n",
            "         -0.3436, -0.9537, -0.0035, -0.0945,  0.4291,  0.0391, -0.9602,  0.4497,\n",
            "          0.5135,  0.4913,  0.0608,  0.9948,  1.0000,  0.9810,  0.8865,  0.7961,\n",
            "         -0.9894, -0.5122,  1.0000, -0.8521, -1.0000, -0.9412, -0.6633,  0.3110,\n",
            "         -1.0000, -0.1468, -0.1235, -0.9465, -0.0891,  0.9796,  0.9700, -1.0000,\n",
            "          0.9324,  0.9259, -0.4503,  0.4591, -0.1785,  0.9819,  0.2285,  0.4423,\n",
            "         -0.2615,  0.4124, -0.5252, -0.8534,  0.0365, -0.0670,  0.8944,  0.1913,\n",
            "         -0.4782, -0.9402,  0.2293, -0.1581, -0.2440, -0.9604, -0.1924, -0.0555,\n",
            "          0.5484,  0.1915,  0.2038, -0.7367,  0.2698, -0.7307,  0.3715,  0.5640,\n",
            "         -0.9386, -0.5717,  0.3818, -0.2775,  0.1536, -0.9608,  0.9702, -0.3502,\n",
            "          0.1524,  1.0000,  0.3876, -0.9001,  0.2547,  0.1857,  0.0832,  1.0000,\n",
            "          0.3811, -0.9852, -0.4053,  0.2576, -0.3923, -0.4125,  0.9994, -0.1463,\n",
            "         -0.0428,  0.2818,  0.9899, -0.9923,  0.8351, -0.8563, -0.9634,  0.9617,\n",
            "          0.9268, -0.4225, -0.7369,  0.1318,  0.1107,  0.2294, -0.8914,  0.6082,\n",
            "          0.4665, -0.0720,  0.8555, -0.7973, -0.3478,  0.4201, -0.1762,  0.0761,\n",
            "          0.2823,  0.4571, -0.1350,  0.1190, -0.3509, -0.4039, -0.9556,  0.0262,\n",
            "          1.0000, -0.2164,  0.0569, -0.2296, -0.1003, -0.1827,  0.4036,  0.4715,\n",
            "         -0.3293, -0.8471, -0.0518, -0.8453, -0.9935,  0.6732,  0.2284, -0.1968,\n",
            "          0.9998,  0.5194,  0.2326,  0.1718,  0.7497, -0.0192,  0.4518, -0.0327,\n",
            "          0.9765, -0.3259,  0.3491,  0.7471, -0.3186, -0.3019, -0.5725,  0.0563,\n",
            "         -0.9206,  0.0572, -0.9589,  0.9565,  0.3109,  0.3348,  0.1635, -0.0619,\n",
            "          1.0000, -0.6020,  0.5309, -0.3723,  0.6636, -0.9851, -0.6789, -0.4312,\n",
            "         -0.1435, -0.0827, -0.2497,  0.1323, -0.9786, -0.0474, -0.0304, -0.9444,\n",
            "         -0.9927,  0.2508,  0.6172,  0.1679, -0.7980, -0.6078, -0.4906,  0.4646,\n",
            "         -0.1934, -0.9396,  0.5453, -0.3000,  0.4329, -0.3340,  0.4408, -0.2058,\n",
            "          0.8344,  0.1265, -0.0307, -0.2098, -0.8340,  0.7114, -0.7410,  0.0518,\n",
            "         -0.1481,  1.0000, -0.3100,  0.1461,  0.7011,  0.6334, -0.2857,  0.1618,\n",
            "          0.0966,  0.2955, -0.0981, -0.1832, -0.6208, -0.3013,  0.4337,  0.0283,\n",
            "         -0.2959,  0.7579,  0.4711,  0.3666, -0.0531,  0.0914,  0.9969, -0.2267,\n",
            "         -0.1165, -0.5533, -0.1262, -0.3575, -0.2124,  1.0000,  0.3679,  0.0604,\n",
            "         -0.9936, -0.2000, -0.9208,  0.9999,  0.8511, -0.8783,  0.5650,  0.2405,\n",
            "         -0.2859,  0.6935, -0.2598, -0.2655,  0.2893,  0.2862,  0.9774, -0.4575,\n",
            "         -0.9764, -0.5964,  0.3966, -0.9575,  0.9939, -0.5326, -0.2349, -0.4376,\n",
            "         -0.0250,  0.2574,  0.0274, -0.9762, -0.1582,  0.1821,  0.9811,  0.3014,\n",
            "         -0.3820, -0.9007, -0.1151,  0.3936, -0.0680, -0.9449,  0.9809, -0.9313,\n",
            "          0.2600,  1.0000,  0.3860, -0.5243,  0.2401, -0.4410,  0.3253, -0.1413,\n",
            "          0.5428, -0.9466, -0.2817, -0.3262,  0.4330, -0.2120, -0.2457,  0.7247,\n",
            "          0.2134, -0.3430, -0.6305, -0.1214,  0.4871,  0.7498, -0.2957, -0.1829,\n",
            "          0.1699, -0.1391, -0.9264, -0.4167, -0.2995, -0.9991,  0.6411, -1.0000,\n",
            "         -0.1510, -0.5473, -0.2219,  0.8075,  0.3862, -0.1392, -0.7206, -0.0710,\n",
            "          0.6995,  0.6656, -0.2889,  0.2902, -0.6951,  0.1622, -0.1298,  0.3182,\n",
            "          0.1694,  0.6526, -0.2735,  1.0000,  0.1370, -0.3043, -0.9189,  0.3041,\n",
            "         -0.2604,  1.0000, -0.7969, -0.9715,  0.2110, -0.5773, -0.7218,  0.2477,\n",
            "         -0.0304, -0.7015, -0.6577,  0.9111,  0.8219, -0.3693,  0.4537, -0.3062,\n",
            "         -0.3671,  0.0856,  0.1595,  0.9903,  0.2790,  0.8213, -0.2885, -0.0724,\n",
            "          0.9636,  0.2213,  0.6892,  0.2070,  1.0000,  0.3249, -0.8999,  0.2644,\n",
            "         -0.9700, -0.2610, -0.9228,  0.4016,  0.1170,  0.8570, -0.3587,  0.9672,\n",
            "          0.0667,  0.1108, -0.1840,  0.4711,  0.3127, -0.9391, -0.9892, -0.9908,\n",
            "          0.3962, -0.5013, -0.0640,  0.3811,  0.1530,  0.4712,  0.3781, -1.0000,\n",
            "          0.9466,  0.3529,  0.2077,  0.9735,  0.2019,  0.4726,  0.4248, -0.9892,\n",
            "         -0.9203, -0.3418, -0.2910,  0.6572,  0.5584,  0.8190,  0.4319, -0.4171,\n",
            "         -0.4697,  0.4653, -0.8583, -0.9940,  0.4802,  0.0740, -0.8986,  0.9559,\n",
            "         -0.4745, -0.1616,  0.4457,  0.1412,  0.8933,  0.8280,  0.4313,  0.2437,\n",
            "          0.6787,  0.9043,  0.8940,  0.9903, -0.2561,  0.6986, -0.0055,  0.3281,\n",
            "          0.6809, -0.9586,  0.1583,  0.0033, -0.2711,  0.3025, -0.1928, -0.9207,\n",
            "          0.5260, -0.2139,  0.5709, -0.2302,  0.1593, -0.4779, -0.1577, -0.7036,\n",
            "         -0.5208,  0.4676,  0.2335,  0.9372,  0.4775, -0.1995, -0.5655, -0.2336,\n",
            "          0.0798, -0.9315,  0.8288, -0.0946,  0.5294,  0.0223, -0.0744,  0.7821,\n",
            "          0.1236, -0.3705, -0.3959, -0.7528,  0.8145, -0.3204, -0.4786, -0.5135,\n",
            "          0.7306,  0.3208,  0.9981, -0.3959, -0.3492, -0.1118, -0.2872,  0.3596,\n",
            "         -0.1345, -1.0000,  0.2896,  0.2262,  0.1702, -0.3530,  0.1111, -0.0755,\n",
            "         -0.9565, -0.2658,  0.2530, -0.0490, -0.5834, -0.4616,  0.3937,  0.2329,\n",
            "          0.5620,  0.8138, -0.0288,  0.5621,  0.3811,  0.0852, -0.6049,  0.8452]],\n",
            "       grad_fn=<TanhBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Step 5: Data Preparation\n",
        "#### 5.1 Loading dataset and selecting important columns\n",
        "\n"
      ],
      "metadata": {
        "id": "5Z-8UUqwQIxQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')\n"
      ],
      "metadata": {
        "id": "2BJmyCbbVZHn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d5426a-7ca7-44f1-b68b-f5204e6c111d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('/content/gdrive/MyDrive/translated_cleaned_data_1_unsupervised.csv')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "jiowjFcGFqSK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6deb9eaa-1e3b-4be1-856f-7dc6b8c0b010"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0.1.1      reviewerID  \\\n",
              "0           0             0             0               0  A30TL5EWN6DFXT   \n",
              "1           1             1             1               1   ASY55RVNIL0UD   \n",
              "2           2             2             2               2  A2TMXE2AFO7ONB   \n",
              "3           3             3             3               3   AWJ0WZQYMYFQ4   \n",
              "4           4             4             4               4   ATX7CZYFXI1KW   \n",
              "\n",
              "         asin  \\\n",
              "0  120401325X   \n",
              "1  120401325X   \n",
              "2  120401325X   \n",
              "3  120401325X   \n",
              "4  120401325X   \n",
              "\n",
              "                                                                                                                                                                                                reviewText  \\\n",
              "0  Looks Good   Looks Good  They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a produ...   \n",
              "1  Really great product.   Really great product.  These stickers work like the review says they do. They stick on great and they stay on the phone. They are super stylish and I can share them with my...   \n",
              "2  LOVE LOVE LOVE   LOVE LOVE LOVE  These are awesome and make my phone look so stylish! I have only used one so far and have had it on for almost a year! CAN YOU BELIEVE THAT! ONE YEAR!! Great quality!   \n",
              "3  Cute!   Cute!  Item arrived in great time and was in perfect condition. However, I ordered these buttons because they were a great deal and included a FREE screen protector. I never received one. ...   \n",
              "4  leopard home button sticker for iphone 4s   leopard home button sticker for iphone 4s  awesome! stays on, and looks great. can be used on multiple apple products.  especially having nails, it help...   \n",
              "\n",
              "   overall                                       summary title brand  \\\n",
              "0        4                                 Looks Good      NaN   NaN   \n",
              "1        5                      Really great product.      NaN   NaN   \n",
              "2        5                             LOVE LOVE LOVE      NaN   NaN   \n",
              "3        4                                      Cute!      NaN   NaN   \n",
              "4        5  leopard home button sticker for iphone 4s      NaN   NaN   \n",
              "\n",
              "   review_length  \\\n",
              "0             41   \n",
              "1             38   \n",
              "2             40   \n",
              "3             53   \n",
              "4             37   \n",
              "\n",
              "                                                                                                                                                                           cleaned_reviewText  \\\n",
              "0                                                                      looks good look good look good stick good not like round shape always bump siri keep pop irritate not buy product like   \n",
              "1                                                                    really great product really great product sticker work like review say stick great stay phone super stylish share sister   \n",
              "2                                                                        love love love love love love awesome make phone look stylish use one far almost year believe one year great quality   \n",
              "3  cute cute item arrive great time perfect condition however order button great deal include free screen protector never receive one though not big deal would nice get since claim come one   \n",
              "4                                  leopard home button sticker iphone leopard home button sticker iphone awesome stay look great used multiple apple product especially nail help elevate key   \n",
              "\n",
              "   lemmatized_review_length target  y  \n",
              "0                        22   Good  1  \n",
              "1                        19   Good  1  \n",
              "2                        21   Good  1  \n",
              "3                        31   Good  1  \n",
              "4                        23   Good  1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7c590d76-931d-4075-9680-5479cade3b75\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.2</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>Unnamed: 0.1.1</th>\n",
              "      <th>reviewerID</th>\n",
              "      <th>asin</th>\n",
              "      <th>reviewText</th>\n",
              "      <th>overall</th>\n",
              "      <th>summary</th>\n",
              "      <th>title</th>\n",
              "      <th>brand</th>\n",
              "      <th>review_length</th>\n",
              "      <th>cleaned_reviewText</th>\n",
              "      <th>lemmatized_review_length</th>\n",
              "      <th>target</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>A30TL5EWN6DFXT</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Looks Good   Looks Good  They look good and stick good! I just don't like the rounded shape because I was always bumping it and Siri kept popping up and it was irritating. I just won't buy a produ...</td>\n",
              "      <td>4</td>\n",
              "      <td>Looks Good</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>41</td>\n",
              "      <td>looks good look good look good stick good not like round shape always bump siri keep pop irritate not buy product like</td>\n",
              "      <td>22</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>ASY55RVNIL0UD</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Really great product.   Really great product.  These stickers work like the review says they do. They stick on great and they stay on the phone. They are super stylish and I can share them with my...</td>\n",
              "      <td>5</td>\n",
              "      <td>Really great product.</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>38</td>\n",
              "      <td>really great product really great product sticker work like review say stick great stay phone super stylish share sister</td>\n",
              "      <td>19</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>A2TMXE2AFO7ONB</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>LOVE LOVE LOVE   LOVE LOVE LOVE  These are awesome and make my phone look so stylish! I have only used one so far and have had it on for almost a year! CAN YOU BELIEVE THAT! ONE YEAR!! Great quality!</td>\n",
              "      <td>5</td>\n",
              "      <td>LOVE LOVE LOVE</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>40</td>\n",
              "      <td>love love love love love love awesome make phone look stylish use one far almost year believe one year great quality</td>\n",
              "      <td>21</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>AWJ0WZQYMYFQ4</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>Cute!   Cute!  Item arrived in great time and was in perfect condition. However, I ordered these buttons because they were a great deal and included a FREE screen protector. I never received one. ...</td>\n",
              "      <td>4</td>\n",
              "      <td>Cute!</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>53</td>\n",
              "      <td>cute cute item arrive great time perfect condition however order button great deal include free screen protector never receive one though not big deal would nice get since claim come one</td>\n",
              "      <td>31</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>4</td>\n",
              "      <td>ATX7CZYFXI1KW</td>\n",
              "      <td>120401325X</td>\n",
              "      <td>leopard home button sticker for iphone 4s   leopard home button sticker for iphone 4s  awesome! stays on, and looks great. can be used on multiple apple products.  especially having nails, it help...</td>\n",
              "      <td>5</td>\n",
              "      <td>leopard home button sticker for iphone 4s</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>37</td>\n",
              "      <td>leopard home button sticker iphone leopard home button sticker iphone awesome stay look great used multiple apple product especially nail help elevate key</td>\n",
              "      <td>23</td>\n",
              "      <td>Good</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7c590d76-931d-4075-9680-5479cade3b75')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7c590d76-931d-4075-9680-5479cade3b75 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7c590d76-931d-4075-9680-5479cade3b75');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "id": "MhCingpyFqeB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b671fc5a-99f8-4510-fa70-1ab0b4808f01"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194176, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Features of our interest are label column and text column"
      ],
      "metadata": {
        "id": "r3uuTSlSU6pV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['cleaned_reviewText'].sample(5)"
      ],
      "metadata": {
        "id": "C8EZQc9kU512",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80e7d198-352f-4d85-866e-129173aea33d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "125702                             rise pink white zebra combo hard soft impact case iphone rise pink white zebra combo hard soft impact case iphone really love case like way construct screen protector\n",
              "42525                                                                                                           roll tape roll tape guess tape look like work fine no g screen use guy come not cb screen\n",
              "83702     leave everywhere leave everywhere ever lose stylus somewhere desk could not find really need pack styluses keep one desk desk drawer purse car basically one anywhere well make fit stylus need\n",
              "17209                                                                                 excellent product excellent product great item set easy quality speaker clear play music nicely phone call pleasant\n",
              "42402                                                                                                           love love love kind screen protector fingerprint not show like one look like phone screen\n",
              "Name: cleaned_reviewText, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UUaNHf7Bjylv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_copy=df.copy(deep=True)"
      ],
      "metadata": {
        "id": "rEP-Fmr-f3a7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample data as original data has 1,94,176 records which is very heavy for computation on BERT model and google colab is crashing even after using GPUs"
      ],
      "metadata": {
        "id": "c6aub52JgGsl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3PKjDRUhBSL",
        "outputId": "b8bcf954-8f2e-44e0-8a0a-17d9436791da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Unnamed: 0                   int64\n",
              "Unnamed: 0.2                 int64\n",
              "Unnamed: 0.1                 int64\n",
              "Unnamed: 0.1.1               int64\n",
              "reviewerID                  object\n",
              "asin                        object\n",
              "reviewText                  object\n",
              "overall                      int64\n",
              "summary                     object\n",
              "title                       object\n",
              "brand                       object\n",
              "review_length                int64\n",
              "cleaned_reviewText          object\n",
              "lemmatized_review_length     int64\n",
              "target                      object\n",
              "y                            int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].value_counts())\n",
        "print(df['target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3wI1N5QhExX",
        "outputId": "95a0a8de-8195-4e19-9344-4cc33a067ce2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good       148423\n",
            "Bad         24325\n",
            "Neutral     21428\n",
            "Name: target, dtype: int64\n",
            "Good       0.764374\n",
            "Bad        0.125273\n",
            "Neutral    0.110353\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0rBQOEUnj_mB",
        "outputId": "6daed4a2-d371-4d6b-f3f9-b959e28662a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(194176, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QJoTx1Jmkbs9",
        "outputId": "940af4fa-38ba-40a1-f445-25f1c49c5024"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good       0.764374\n",
            "Bad        0.125273\n",
            "Neutral    0.110353\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['y_value']=df['target'].map({'Good':2,'Neutral':1,'Bad':0})"
      ],
      "metadata": {
        "id": "0k_ozNw4hPun"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#df['y_value'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8eSPYrDjidhn",
        "outputId": "8a277d3e-24bb-454c-dce3-d1809966845e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    148423\n",
              "0     24325\n",
              "1     21428\n",
              "Name: y_value, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N=20000\n",
        "df=df.groupby('target', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(df))))).sample(frac=1).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "BLtzKdDyj3YT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df1.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeOI9CP4kJmP",
        "outputId": "0fc41723-5145-4241-98d0-856b19ea897a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Good       15287\n",
              "Bad         2505\n",
              "Neutral     2207\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4Wvk62ZkxzV",
        "outputId": "eaf92a92-94ad-4a4b-faa9-0a3de7db22c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(19999, 16)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1.target.value_counts(normalize=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1_K3SZ_Mkn0b",
        "outputId": "4e755741-7bf5-473b-8f87-0274b5b0c071"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Good       0.764388\n",
              "Bad        0.125256\n",
              "Neutral    0.110356\n",
              "Name: target, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['target'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "57QLFNhbimng",
        "outputId": "04a99a5e-2b86-4c2e-f6e8-40e823542fab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Good       15287\n",
              "Bad         2505\n",
              "Neutral     2207\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Note, we have maintained the ratio of target variable values in the sampled data of 50,000 records\n"
      ],
      "metadata": {
        "id": "u9gkY_6RitEA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Distribution of Tweets (label)\n"
      ],
      "metadata": {
        "id": "B56ebuSLV4tv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df['target'].value_counts())\n",
        "print(df['target'].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "S68Qc7xaU5-i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90a0f97c-3bca-4914-e5cb-89eb9ba1cf07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Good       15287\n",
            "Bad         2505\n",
            "Neutral     2207\n",
            "Name: target, dtype: int64\n",
            "Good       0.764388\n",
            "Bad        0.125256\n",
            "Neutral    0.110356\n",
            "Name: target, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sabing value counts to a list\n",
        "class_counts=df['target'].value_counts().to_list()"
      ],
      "metadata": {
        "id": "rSCfceNCWF7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_counts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2XEc5-0wjCOi",
        "outputId": "581c2959-361a-47a0-bf67-8098909a6b8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[15287, 2505, 2207]"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.2 Text cleaning\n",
        "- Removing twitter usernames\n",
        "- Removing links (starting with https)\n",
        "- If needed removing hashtags"
      ],
      "metadata": {
        "id": "M5liMLrhWVu9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "def preprocess(text):\n",
        "  # converting text tolower case\n",
        "  text=text.lower()\n",
        "  # remove user mentions\n",
        "  text=re.sub(r'@[A-Za-z0-9]+','',text)\n",
        "  # remove hashtags if needed keep for now\n",
        "  #text=re.sub(r'#[A-Za-z0-9]+','',text)\n",
        "\n",
        "  # remove links\n",
        "  text=re.sub(r'http\\S+','',text)\n",
        "\n",
        "  # Split tokens so that extra spaces which were added due to above substitution are removed\n",
        "  tokens=text.split()\n",
        "\n",
        "  # join tokens by space\n",
        "  return ' '.join(tokens)\n",
        "  '''"
      ],
      "metadata": {
        "id": "_hzAuGhWWOxo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "06afee3a-4c70-40c2-fdf4-7e58ef75fe98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\ndef preprocess(text):\\n  # converting text tolower case\\n  text=text.lower()\\n  # remove user mentions\\n  text=re.sub(r'@[A-Za-z0-9]+','',text)\\n  # remove hashtags if needed keep for now\\n  #text=re.sub(r'#[A-Za-z0-9]+','',text)\\n\\n  # remove links\\n  text=re.sub(r'http\\\\S+','',text)\\n\\n  # Split tokens so that extra spaces which were added due to above substitution are removed\\n  tokens=text.split()\\n\\n  # join tokens by space\\n  return ' '.join(tokens)\\n  \""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# using apply function to apply this preprocess function on each row of the text column\n",
        "df['cleaned_text']=df['text'].apply(preprocess)\n",
        "'''"
      ],
      "metadata": {
        "id": "6ro0nCFFWO4Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b6729cb-7cef-4d8c-bea5-2dc200d04b3c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# using apply function to apply this preprocess function on each row of the text column\\ndf['cleaned_text']=df['text'].apply(preprocess)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()[['airline_sentiment','text','cleaned_text']]"
      ],
      "metadata": {
        "id": "ao3KcY3IXh8i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving cleaned text and labels to variables\n",
        "text=df['cleaned_reviewText'].values\n",
        "labels=df['target'].values"
      ],
      "metadata": {
        "id": "WQma0Wu3XupG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(text))\n",
        "print(type(labels))\n",
        "print(text.shape)\n",
        "print(labels.shape)"
      ],
      "metadata": {
        "id": "-wSZ7dptXuiL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3013f2da-45d7-42d7-a354-0ad881aef105"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "<class 'numpy.ndarray'>\n",
            "(19999,)\n",
            "(19999,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text[50:55]"
      ],
      "metadata": {
        "id": "ue1SY1WpYDtg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1296199-d68d-4fdf-e0bc-8b0bd8b372d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['month still like new month still like new wanted something would provide little protection easy take onoff help grip read review say loses shape mine fit like begin grant not take much maybe constantly take lose shapewhat like gnarled grip side save drop phone handful time case not add much bulk great feel looks good inexpensive need high protection not youget otterbox otherwise satisfied case',\n",
              "       'five star five star daughter love',\n",
              "       'great auto charger samsung galaxy siii great auto charger samsung galaxy siii great charger galaxy device cord long enough use plug location car also coil not hang get way well make device well expect write delivered quickly good packaging',\n",
              "       'good quality good quality color nice sticker stay phone without peel plus easy put phone',\n",
              "       'rescue rescue drop note ii crack screen fortunately across street verizon store immediately take tech recommend one protector stabilize crack immediately purchase three packlong story sort week three crack still stabilize respect protector work fact tell one phone drop possibility screen would not crack severely apt believe no evidence make claim eventually replace phone sure first thing put one protector itinstallation relatively simple say front verizon tech perform watch clean screen thoroughly clean cloth come set carefully lined protector screen pull back tabs separate backing protector use provide plastic card smooth make sure no bubblesgranted tech probably instal hundred protector make look easy however fact verizon carry protector endorsement plus not screen stabilize display clear phone brand new not notice loss sensitivity use finger spen use phone functionsoverall worth every penny save phone not know never think use one past sure always use screen protector subsequent phone brand intend use'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels[50:55]"
      ],
      "metadata": {
        "id": "UYuvLxqdY60I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dad453d4-78cc-415d-e633-15351b5b4bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Good', 'Good', 'Good', 'Good', 'Good'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5.3 Preparing input and output data \n",
        "- **Preparing target input**\n"
      ],
      "metadata": {
        "id": "c0lMweSgYV5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Using label encoder, convert textual labels (positive, negative, neutral) into numners\n",
        "le=LabelEncoder()\n",
        "\n",
        "#fit and transform target strings to a number\n",
        "labels=le.fit_transform(labels)"
      ],
      "metadata": {
        "id": "PVo5wi1DYVYY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "id": "pAeLM2U_XuXs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498aec3b-2797-454e-c58a-fe746a64ee1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Bad', 'Good', 'Neutral'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "lQ1I_DzpZS0M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85179221-de15-4490-f6f0-5e8ac6fdc626"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, ..., 1, 1, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(labels)"
      ],
      "metadata": {
        "id": "qVz9jb22J9C2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61e61b47-829b-42bc-f0be-f1143b82a848"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Visualize length of tweets\n"
      ],
      "metadata": {
        "id": "YXc7rBmLZci3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num=[len(i.split()) for i in text]\n",
        "plt.hist(num,bins=30)\n",
        "plt.title('Histogram: Length of sentences')\n",
        "plt.xlabel('Length of sentences')\n",
        "plt.ylabel('Count of sentences')"
      ],
      "metadata": {
        "id": "o8O_ueeqZYZp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "outputId": "da6bcdd9-7276-4735-eee6-5e48ddf82140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Count of sentences')"
            ]
          },
          "metadata": {},
          "execution_count": 122
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- It can be observed that most of the sentences (~95%) have length of 200 words. Hence, we select max_length as 200 for all the tweets in our dataset. \n",
        "- All the sequences will be paddded to 200.\n",
        "- How to decide?\n",
        "If you choose too big number, then most of the positions in your sequence will have padded tokens. So choose a number near to your max lenght of text sequence"
      ],
      "metadata": {
        "id": "JYONnhERZ8kH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Preparing Textual Input**"
      ],
      "metadata": {
        "id": "g3oQrOYQcaEi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_len=200 # This is a hyper parameter which can be tuned"
      ],
      "metadata": {
        "id": "RYJB3P-jZ6hD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Using bert tokenizer, convert text sequences into numerical vectors"
      ],
      "metadata": {
        "id": "fBR5wDuKcF9K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an empty list to save integer sequence\n",
        "sent_id=[]\n",
        "\n",
        "# iterate over each tweet and encode it using bert tokenizer\n",
        "for i in notebook.tqdm(range(len(text))):\n",
        "  encoded_sent=tokenizer.encode(text[i],\n",
        "                                add_special_tokens=True,\n",
        "                                max_length= max_len,\n",
        "                                truncation=True,\n",
        "                                pad_to_max_length='right'\n",
        "                                )\n",
        "  \n",
        "  # save integer sequence to a list\n",
        "  sent_id.append(encoded_sent)"
      ],
      "metadata": {
        "id": "ODFQsKJuZ6pJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104,
          "referenced_widgets": [
            "166aa737ed6d413db23fca3e308e2f89",
            "3176e8b37ce243969707a8c6e51967ce",
            "c4ec754975b048a1853e1b326e4f70d7",
            "bfe44a30a477436d9205cf1b6a6e0176",
            "43c86486da9143a49632e89b8811185d",
            "8063cb2b012d4e12b778b22a5cf09a70",
            "f59934faf4524c77bd55f88d246cf4fe",
            "bafada90012e47c390d968641b9f0016",
            "a1937a07ee294aa38bcc70318b4cc8fd",
            "8afd0f9cafcb40809897800c8e10e0c0",
            "d197fdf960404d39a4883d599d3afe46"
          ]
        },
        "outputId": "fb02e10b-f8d0-46db-cbd6-4f868b9dc2f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/19999 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "166aa737ed6d413db23fca3e308e2f89"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/transformers/tokenization_utils_base.py:2339: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[0])"
      ],
      "metadata": {
        "id": "5h-Y1qCLbhJT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c82ffda-25f4-4e86-e24a-0e01bd4642b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fit perfectally tottally love fit perfectally tottally love totally surround pod still fit dock station take little get use replace dock station like one clock radio etc easy get hold button dock port ear phone port thing really not really like really no protection wheel selector center button mostly want something protect screen not cheep make well\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(sent_id[0])"
      ],
      "metadata": {
        "id": "Gbp5jAmjbc45",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "344ce95f-c774-4302-e51d-0a7f3d0ab696"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 4906, 3819, 3973, 2000, 28200, 2135, 2293, 4906, 3819, 3973, 2000, 28200, 2135, 2293, 6135, 15161, 17491, 2145, 4906, 8946, 2276, 2202, 2210, 2131, 2224, 5672, 8946, 2276, 2066, 2028, 5119, 2557, 4385, 3733, 2131, 2907, 6462, 8946, 3417, 4540, 3042, 3417, 2518, 2428, 2025, 2428, 2066, 2428, 2053, 3860, 5217, 27000, 2415, 6462, 3262, 2215, 2242, 4047, 3898, 2025, 18178, 13699, 2191, 2092, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(sent_id)"
      ],
      "metadata": {
        "id": "BtZpwOB1KGk9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "929a41be-9c3b-4ba3-9ff8-0e6866253ac8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {},
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- You can see here that '.' i.e. full stop is represented by different number (1012). \n",
        "- 101 represents CLS token and 102 represents SEP token"
      ],
      "metadata": {
        "id": "SzWSIGQVuMjD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Create Attention masks"
      ],
      "metadata": {
        "id": "yJemoraWcvoy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attention_mask=[]\n",
        "\n",
        "for sent in sent_id:\n",
        "  attn_mask=[int(token_id>0) for token_id in sent]\n",
        "  attention_mask.append(attn_mask)"
      ],
      "metadata": {
        "id": "dKc7plQVZ6wQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(attention_mask)"
      ],
      "metadata": {
        "id": "4hZM8zZmJ36P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "504213fd-7a7d-4994-e4c1-e52d03d84ec9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "19999"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 6: Training and Validation Data"
      ],
      "metadata": {
        "id": "6rOwHCYbdN_4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting input data\n",
        "train_inputs,validation_inputs, train_labels,validation_labels=train_test_split(sent_id,labels,random_state=2018, test_size=0.1,stratify=labels)\n",
        "# Splitting masks\n",
        "train_mask,validation_mask,_,_= train_test_split(attention_mask,labels,random_state=2018,test_size=0.1,stratify=labels)\n",
        "\n"
      ],
      "metadata": {
        "id": "x7gnLpisFBIQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- For both the labels and attention mask, keeping random_state=2018 same, ensures that same indices are randomly being picked up from both the lists.\n",
        "-stratify=label ensures the ratio of labels in original dataset is maintained in the train and validation set."
      ],
      "metadata": {
        "id": "-WTmrku8Gkul"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 7: Define Dataloaders"
      ],
      "metadata": {
        "id": "usgyOXquGkyE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting all inputs and labels into torch tensors which is the required datatype for the BERT model\n",
        "\n",
        "train_inputs=torch.tensor(train_inputs)\n",
        "train_labels=torch.tensor(train_labels)\n",
        "train_mask=torch.tensor(train_mask)\n",
        "\n",
        "validation_inputs=torch.tensor(validation_inputs)\n",
        "validation_labels=torch.tensor(validation_labels)\n",
        "validation_mask=torch.tensor(validation_mask)"
      ],
      "metadata": {
        "id": "dOFPWdq1dDpq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- In a dataset, we store indices and it's corresponding labels\n",
        "- Where as in Dataloaders, an iterator is wrapped aroound the dataset so that sampling can be performed easlily (by accessing indices of rows). With the help of iterator, it is easy to iterate through the batches and understand encoded sequences.\n",
        "- Basically Dataloader takes in dataset and sampler to return an iterable over dataset\n",
        "- The output of DataLoader is input batch, masks batch and labels batch.\n",
        "- batch_size is needed for training, and in order to fine-tune BERT on a specific task, the authors recommend a batch size of 16 or 32"
      ],
      "metadata": {
        "id": "cmrAwbK8Na-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "validation_inputs"
      ],
      "metadata": {
        "id": "0QSnK2l7KQ_w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9792d061-5be4-427d-9543-ed3a28599ffa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 101, 2048, 3538,  ...,    0,    0,    0],\n",
              "        [ 101, 2147, 2066,  ...,    0,    0,    0],\n",
              "        [ 101, 2204, 2204,  ...,    0,    0,    0],\n",
              "        ...,\n",
              "        [ 101, 3737, 2674,  ...,    0,    0,    0],\n",
              "        [ 101, 2994, 2994,  ...,    0,    0,    0],\n",
              "        [ 101, 2360, 9543,  ...,    0,    0,    0]])"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# batch size\n",
        "batch_size=32\n",
        "\n",
        "# Creating Tensor Dataset for training data\n",
        "train_data=TensorDataset(train_inputs,train_mask,train_labels)\n",
        "\n",
        "# Defining a random sampler during training\n",
        "train_sampler=RandomSampler(train_data)\n",
        "\n",
        "# Creating iterator using DataLoader. This iterator supports batching, customized data loading order\n",
        "train_dataloader=DataLoader(train_data,sampler=train_sampler,batch_size=batch_size )\n",
        "\n",
        "# Creating tensor dataset for validation data\n",
        "validation_data=TensorDataset(validation_inputs,validation_mask,validation_labels)\n",
        "\n",
        "# Defining a sequential sampler during validation, bcz there is no need to shuffle the data. We just need to validate\n",
        "validation_sampler=SequentialSampler(validation_data)\n",
        "\n",
        "# Create an iterator over validation dataset\n",
        "validation_dataloader=DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)\n",
        "\n"
      ],
      "metadata": {
        "id": "jSetRnG8dDxP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#validation_dataloader.next()"
      ],
      "metadata": {
        "id": "51hN4E21J-ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Tensor Dataset: It creates dataset by combining different tensors\n",
        "- DataLoader: Loads the dataset in the form of batchs\n",
        "- Random Sampler: Samples batches randomly from the data loader\n",
        "- Sequential Sampler: It samples the batches sequentially from the data loader"
      ],
      "metadata": {
        "id": "GaJtyl2PO89p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an iterator object\n",
        "iterator=iter(train_dataloader)\n",
        "\n",
        "# loads batch data\n",
        "sent_id,mask,target=iterator.__next__()"
      ],
      "metadata": {
        "id": "T0wc7v9xRO0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id.shape"
      ],
      "metadata": {
        "id": "IsOyCRPPRmwY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f61d4c2-a3d3-4c0d-9ddf-a0ddbcc4503e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([32, 200])"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 32 is a batch size (32 text records) and 25 is the length of sequence"
      ],
      "metadata": {
        "id": "NhvjVaBsSQ3B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sent_id"
      ],
      "metadata": {
        "id": "xr58fcWsRnRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ff3576f-6445-4ebc-8488-2632ada7319d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  101,  3013, 10982,  ...,     0,     0,     0],\n",
              "        [  101,  2844, 10514,  ...,     0,     0,     0],\n",
              "        [  101, 25933,  4371,  ...,  2028,  5080,   102],\n",
              "        ...,\n",
              "        [  101,  2204,  3259,  ...,  3042,  2377,   102],\n",
              "        [  101,  3565,  2686,  ...,     0,     0,     0],\n",
              "        [  101,  3737,  2307,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=bert(sent_id,attention_mask=mask)"
      ],
      "metadata": {
        "id": "Lu7GdnfXRnbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hidden_states=outputs[0]\n",
        "CLS_hidden_state=outputs[1]\n",
        "\n",
        "print(\"Shape of Hidden States:\",hidden_states.shape)\n",
        "print(\"Shape of CLS Hidden State:\",CLS_hidden_state.shape)"
      ],
      "metadata": {
        "id": "ENs92ZMwRnl_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b250a6f9-0dfa-4d15-b6dd-1508ebe3373e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of Hidden States: torch.Size([32, 200, 768])\n",
            "Shape of CLS Hidden State: torch.Size([32, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(hidden_states)"
      ],
      "metadata": {
        "id": "5NeWy2vKQFmi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887657cf-29f5-421f-e5f6-67499322f47e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 8: Fine-Tuning BERT"
      ],
      "metadata": {
        "id": "OH6x4-__TFB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The pretrained BERT model is trained on large amount of general corpus. Finetuning the pretrained model will help us capture domain specific features from our dataset.\n",
        "- Here, we will fine tune only head layer. i.e. Head Layer is the dense layer added on the top of the pre-trained bert model. This layer is used for classification tasks."
      ],
      "metadata": {
        "id": "rRahFehuS4M8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Steps to Follow\n",
        "\n",
        "1. Turn off Gradients: This step is freezes the parameters of BERT model, so that when we fine tune the model, the parameters of BERT model are not affected, only weights of head part are affected.\n",
        "\n"
      ],
      "metadata": {
        "id": "IQbCIa6cKaC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# turn off the gradient of all parameters\n",
        "\n",
        "for param in bert.parameters():\n",
        "  param.requires_grad=False"
      ],
      "metadata": {
        "id": "OsJg7W5zSyU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Define Model Architecture\n",
        "\n"
      ],
      "metadata": {
        "id": "KXinhjd8LKtE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "# Classifier is a sub class of nn.Module from pytorch\n",
        "class classifier(nn.Module):\n",
        "\n",
        "  # define the layers and wrappers used by model\n",
        "  def __init__(self,bert):\n",
        "    #Constructor. \n",
        "    super(classifier,self).__init__() #using super() which is a proxy instance of super class-nn.Module to access the __init__() method of nn.Module\n",
        "    # bert model\n",
        "    self.bert=bert\n",
        "\n",
        "    #dense layer 1\n",
        "    self.fc1=nn.Linear(768,512) # the output of BERT has 768 and 512 can be any hyperparameter which we can tune\n",
        "\n",
        "    #dense layer 2 (output layer)\n",
        "    self.fc2=nn.Linear(512,3)   # 3 because our class label has 3 categories\n",
        "\n",
        "    # droupout layer\n",
        "    self.dropout=nn.Dropout(0.1)\n",
        "\n",
        "    # relu activation function\n",
        "    self.relu=nn.ReLU()\n",
        "\n",
        "    #softmax activation function\n",
        "    self.softmax=nn.LogSoftmax(dim=1)\n",
        "\n",
        "\n",
        "  # Define the forward pass\n",
        "  def forward(self,sent_id,mask):\n",
        "\n",
        "    # pass the inputs to the model\n",
        "    all_hidden_states,cls_hidden_state=self.bert(sent_id,attention_mask,return_dict=False)\n",
        "\n",
        "    # pass CLS hidden state to dense layer\n",
        "    x=self.fc1(cls_hidden_state)\n",
        "\n",
        "    # Apply ReLU activation function\n",
        "    x=self.relu(x)\n",
        "\n",
        "    # Apply dropout\n",
        "    x=self.dropout(x)\n",
        "\n",
        "    # pass input to the output layer\n",
        "    x=self.fc2(x)\n",
        "\n",
        "    # apply softmax activation\n",
        "    x=self.softmax(x)\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "OlL69BALLEzJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class classifier(nn.Module):\n",
        "\n",
        "    #define the layers and wrappers used by model\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      #constructor\n",
        "      super(classifier, self).__init__()\n",
        "\n",
        "      #bert model\n",
        "      self.bert = bert \n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      #dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,3)\n",
        "      \n",
        "      #dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "\n",
        "      #relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      all_hidden_states, cls_hidden_state = self.bert(sent_id, attention_mask=mask, return_dict=False)\n",
        "      \n",
        "      #pass CLS hidden state to dense layer\n",
        "      x = self.fc1(cls_hidden_state)\n",
        "\n",
        "      #Apply ReLU activation function\n",
        "      x = self.relu(x)\n",
        "\n",
        "      #Apply Dropout\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      #pass input to the output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      #apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "6x6ZtgHIRmRH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Why do you need dropout?**\n",
        "- Dropout means randomly ignoring neurons during the training phase to reduce over fitting.\n",
        "- A fully connected neural network accumulates most of the parameters and as a result, neurons develop co-dependency amongst each other during training phase. This controls the individual power of each neuron and leads to voer-fitting of training data"
      ],
      "metadata": {
        "id": "3ft1pLyA6f69"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# create the model\n",
        "model=classifier(bert)\n",
        "\n",
        "# push the model to GPU, if available\n",
        "model=model.to(device)"
      ],
      "metadata": {
        "id": "FP1Qel3cLFJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model arcitecture\n",
        "model"
      ],
      "metadata": {
        "id": "6DDz8xaTLFQS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f8be35f7-9ed8-4091-e384-deae0f325a56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "classifier(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (fc1): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (fc2): Linear(in_features=512, out_features=3, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (relu): ReLU()\n",
              "  (softmax): LogSoftmax(dim=1)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- We can see that fc1, fc2 are the 2 additional linear layers we've added to the BERT model\n"
      ],
      "metadata": {
        "id": "IKb3uSjqN0TP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(sent_id)"
      ],
      "metadata": {
        "id": "7MuTSm7yQb-7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "958d1bd6-98d1-4c25-a1ec-d46a688b0fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Tensor"
            ]
          },
          "metadata": {},
          "execution_count": 146
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# push the tensors to GPU\n",
        "sent_id=sent_id.to(device)\n",
        "mask=mask.to(device)\n",
        "target=target.to(device)\n"
      ],
      "metadata": {
        "id": "rZoIke-BLFY7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pass inputs to the model\n",
        "outputs=model(sent_id,mask)"
      ],
      "metadata": {
        "id": "r9xx19zfOG5y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- The forward method is called from the __call__ function of nn.Module when we run the above line of code. \n",
        "- When the classifier class is instantiated, all the statements withi __init__() class are executed. i.e. constructor is executed.\n",
        "- When we run the classifier on input data, via model(sent_id, mask) the __call__ method is invoked.\n",
        "- The classifier class simply inherits the __call__ method of the nn.Module class and when we run classifier(input), the forward method is called."
      ],
      "metadata": {
        "id": "54dfhVHl-ln4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs=outputs.to(device)"
      ],
      "metadata": {
        "id": "iahTu9MVZAWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(outputs)"
      ],
      "metadata": {
        "id": "BlwUoihOOGgz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eeb3f0ab-d515-4b24-8832-ea598cff35e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-1.1076, -0.9496, -1.2631],\n",
            "        [-1.1393, -0.9869, -1.1802],\n",
            "        [-1.1486, -0.8917, -1.2984],\n",
            "        [-1.0606, -0.9406, -1.3342],\n",
            "        [-1.1491, -0.9781, -1.1808],\n",
            "        [-1.1499, -0.8981, -1.2874],\n",
            "        [-1.1347, -0.9033, -1.2973],\n",
            "        [-1.1664, -0.8929, -1.2763],\n",
            "        [-1.1508, -0.9760, -1.1816],\n",
            "        [-1.0739, -0.9846, -1.2561],\n",
            "        [-1.1528, -0.9785, -1.1764],\n",
            "        [-1.0774, -0.9531, -1.2948],\n",
            "        [-1.1712, -0.9093, -1.2475],\n",
            "        [-1.0865, -0.9504, -1.2874],\n",
            "        [-1.1131, -1.0491, -1.1357],\n",
            "        [-1.1358, -0.9177, -1.2751],\n",
            "        [-1.1950, -0.9278, -1.1978],\n",
            "        [-1.0935, -0.9823, -1.2361],\n",
            "        [-1.1840, -0.9333, -1.2016],\n",
            "        [-1.0324, -1.0320, -1.2463],\n",
            "        [-1.0773, -0.9727, -1.2679],\n",
            "        [-1.1800, -0.9279, -1.2128],\n",
            "        [-1.1015, -1.0493, -1.1475],\n",
            "        [-1.1479, -0.9860, -1.1723],\n",
            "        [-1.1365, -0.9141, -1.2794],\n",
            "        [-1.1699, -0.8307, -1.3710],\n",
            "        [-1.0956, -0.9593, -1.2641],\n",
            "        [-1.1412, -0.9307, -1.2507],\n",
            "        [-1.1028, -0.9269, -1.3009],\n",
            "        [-1.1766, -0.9346, -1.2076],\n",
            "        [-1.1874, -0.9055, -1.2357],\n",
            "        [-1.1337, -1.0180, -1.1494]], device='cuda:0',\n",
            "       grad_fn=<LogSoftmaxBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Now that we have defined the model arcitecture, let's see how many trainable parameters we have.\n",
        "- numel() returns the total number of elemtns in input tensor. \n",
        "- If we would have trained the parameters in BERT pretrained model, then this number of trainable parameters would have been in millions."
      ],
      "metadata": {
        "id": "QHIlgh0gWUS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# no. of trainable parameters\n",
        "def count_parameters(model):\n",
        "  return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')\n"
      ],
      "metadata": {
        "id": "6slkc64hOHGK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54582f8e-1ce9-4231-b1ce-ecb7ee9d4856"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The model has 395,267 trainable parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Define Optimizer and Loss\n",
        "\n"
      ],
      "metadata": {
        "id": "TNmXN8aCXKIk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adam optmizer\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)"
      ],
      "metadata": {
        "id": "FEPc9UNGOHOw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Understnding class distribution\n",
        "\n",
        "keys=['0','1','2']\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(5,5))\n",
        "\n",
        "# plot bar chart\n",
        "plt.bar(keys,class_counts)\n",
        "\n",
        "# set title\n",
        "plt.title('Class Distribution')\n",
        "plt.xticks(np.arange(3),['Good','Bad','Neutral'])"
      ],
      "metadata": {
        "id": "d74YovTcXUKJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "24727b13-f790-4f71-9650-3f4cfa5997ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([<matplotlib.axis.XTick at 0x7fad47bc28e0>,\n",
              "  <matplotlib.axis.XTick at 0x7fad4a820460>,\n",
              "  <matplotlib.axis.XTick at 0x7fad4a82c3d0>],\n",
              " [Text(0, 0, 'Good'), Text(1, 0, 'Bad'), Text(2, 0, 'Neutral')])"
            ]
          },
          "metadata": {},
          "execution_count": 154
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 360x360 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# library for array processing\n",
        "import numpy as np\n",
        "\n",
        "# computing the class weights\n",
        "class_weights=compute_class_weight(class_weight='balanced',classes=np.unique(labels),y=labels)\n",
        "print(\"Class Weights:\",class_weights)"
      ],
      "metadata": {
        "id": "Ks7eGznVXUko",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d262e6a9-5a36-4467-d023-fdd82bf3801c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Weights: [2.66121091 0.43607859 3.0205407 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting a list of class weights into a tensor\n",
        "weights=torch.tensor(class_weights, dtype=torch.float)\n",
        "\n",
        "# transferring weights to GPU\n",
        "weights=weights.to(device)\n",
        "\n",
        "# define the loss function\n",
        "cross_entropy=nn.NLLLoss(weight=weights)"
      ],
      "metadata": {
        "id": "o41P488pXUty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing the loss\n",
        "print(target)\n",
        "#print(outputs)\n",
        "loss=cross_entropy(outputs,target)\n",
        "print('Loss: ',loss)"
      ],
      "metadata": {
        "id": "_AkEekSgXU5M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf0cc72c-040e-40ae-ca71-9c83d82b6b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 0, 1, 1, 2, 1, 1,\n",
            "        1, 0, 1, 1, 1, 0, 1, 2], device='cuda:0')\n",
            "Loss:  tensor(1.1200, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function for computing time in hh:mm:ss\n",
        "\n",
        "def format_time(elapsed):\n",
        "\n",
        "  elapsed_rounded=int(round(elapsed))\n",
        "\n",
        "  # format intp hh:mm:ss\n",
        "  return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "metadata": {
        "id": "59j5udXHaMBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "4. Define Train and Evaluate\n",
        "\n",
        "The deep learning model is trained in the form of epochs where in each epoch consists of several batches. \n",
        "\n",
        "- During **Training Phase**, for each batch, we need to take following steps:\n",
        "\n",
        "1. Perform Forward Pass\n",
        "2. Compute Loss\n",
        "3. Backpropogate Loss\n",
        "4. Update Weights\n",
        "\n",
        "- In **Evaluation Phase**, for each batch, we need to perform following steps:\n",
        "1. Perform forward pass\n",
        "2. Compute Loss\n",
        "\n",
        "**Training: Epoch -> Batch -> Forward Pass -> Compute Loss -> Backpropogate Loss -> Update Weights**\n",
        "\n",
        "\n",
        "**Evaluation: Epoch -> Batch -> Forward Pass -> Compute Loss**\n",
        "\n",
        "**Epoch**\n",
        "- An epoch refers to one complete pass of the training dataset through the algorithm (through the neural network)\n",
        "- Number of epochs is the number of complete passes of the entire training dataset passing through the training or learning process of the algorithm.\n",
        "- It is the hyper parameter that indicates number of times the learning algorithm will work through the entire dataset."
      ],
      "metadata": {
        "id": "40cusuH50SV3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training Phase**\n",
        "\n",
        "For each epoch, we have a training phase and validation phase. Hence, for each batch, we need to take following steps:\n",
        "  1. Load data ontp the GPU for acceleration\n",
        "  2. Unpack the data inputs and labels\n",
        "  3. Clear out the gradients calculated in previous steps\n",
        "  4. Forward pass (feed input data through week)\n",
        "  5. Backward pass (backpropogation)\n",
        "  6. Update parameters using optimizer.step()\n",
        "  7. Track variables for monitoring progress"
      ],
      "metadata": {
        "id": "reNg_9ZY1-2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a training function for the model:\n",
        "\n",
        "def train():\n",
        "  print('\\n Training')\n",
        "\n",
        "  # set the model on training phase- Dropout layers are activated\n",
        "  model.train()\n",
        "  # recording current time\n",
        "  t0=time.time()\n",
        "  # initialize the loss and accuracy to 0\n",
        "  total_loss,total_accuracy=0,0\n",
        "\n",
        "  # Create an empty list to save the model prediction\n",
        "  total_preds=[]\n",
        "\n",
        "  # for every batch\n",
        "  for step, batch in enumerate(train_dataloader):\n",
        "    #Progress update after every 40 batches\n",
        "    if step % 40==0 and not step==0:\n",
        "      elapsed=format_time(time.time()-t0)         # Calculate elapsed time in minutes\n",
        "      print(' Batch{:>5,} of {:>5,}. Elapsed: {:}.'.format(step,len(train_dataloader),elapsed)) # Print progress\n",
        "    batch=tuple(t.to(device) for t in batch)      # push the batch to GPU\n",
        "\n",
        "    # batch is a part of all the records in train_dataloader. It contains 3 pytorch tensors:\n",
        "    # [0]: input ids\n",
        "    # [1]: attention masks\n",
        "    # [2]: labels\n",
        "\n",
        "    sent_id,mask,labels=batch\n",
        "\n",
        "    #Pytorch doesn't automatically clear previously calculated gradients, hence before performing a backward pass, clear previous gradients\n",
        "    model.zero_grad()\n",
        "\n",
        "    # Perform a forward pass. This returns the model predictions\n",
        "    preds=model(sent_id,mask)\n",
        "\n",
        "    # Compute the loss between actual and predicted values\n",
        "    loss=cross_entropy(preds,labels)\n",
        "\n",
        "    #Accumulate training loss over all the batches, so that we can calculate the average loss at the end\n",
        "    # loss is a tensor containing a single value.\n",
        "    # .itme() method just returns the Python value from the tensor\n",
        "\n",
        "    total_loss=total_loss+loss.item()\n",
        "\n",
        "    # Perform backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "    # During backward pass, information about parameter changes flows backwards, from the output to the hidden layers to the input\n",
        "\n",
        "    optimizer.step() \n",
        "    # Update parameters and take a step using the computed gradient.\n",
        "    # Here, the optimizer dictates the update rule = how the parameters are modified based on their gradients, learning rate and so on.\n",
        "\n",
        "    # The model predictions are stored on GPU, so push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # Accumulate model predicitons of each batch\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  \n",
        "\n",
        "    # Compute the training loss of an epoch\n",
        "  avg_loss=total_loss/len(train_dataloader)\n",
        "\n",
        "  # The prediction are in the form of (no. of batches, size of batch, no. of classes)\n",
        "  # So we need to resahpe the predictions in the form of number of samples x number of classes\n",
        "\n",
        "  total_preds=np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss,total_preds"
      ],
      "metadata": {
        "id": "KrPatVOO0GQX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation Phase**\n",
        "\n",
        "1. Load data onto the GPU for acceleration\n",
        "2. Unpack the data inputs\n",
        "3. Forward Pass\n",
        "4. Compute Loss on validation data]\n",
        "5. Track variables for monitoring"
      ],
      "metadata": {
        "id": "RsXNo63cC3cX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# define a function for evaluating the model\n",
        "\n",
        "def evaluate():\n",
        "  print(\"'n Evaluating....\")\n",
        "\n",
        "  # set the model on validation phase. Here dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  # record the current time\n",
        "  t0=time.time()\n",
        "\n",
        "  # initialize loss and accuracy to 0\n",
        "  total_loss, total_accuracy=0,0\n",
        "\n",
        "  # Create an empty list to save model predicitons\n",
        "  total_preds=[]\n",
        "\n",
        "  # for each batch\n",
        "\n",
        "  for step, batch in enumerate(validation_dataloader):\n",
        "    if step%40==0 and not step ==0:\n",
        "      elapsed=format_time(time.time()-t0)\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "    \n",
        "    batch=tuple(t.to(device) for t in batch)\n",
        "    sent_id,mask,labels=batch\n",
        "      \n",
        "    #deactivate autograd\n",
        "    with torch.no_grad():\n",
        "\n",
        "      preds=model(sent_id,mask)\n",
        "      loss=cross_entropy(preds,labels)\n",
        "      total_loss=total_loss+loss.item()\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "      total_preds.append(preds)\n",
        "    \n",
        "    avg_loss=total_loss/len(validation_dataloader)\n",
        "\n",
        "    total_preds=np.concatenate(total_preds,axis=0)\n",
        "\n",
        "    return avg_loss,total_preds\n"
      ],
      "metadata": {
        "id": "DAwqa5VE0Gdu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#define a function for evaluating the model\n",
        "def evaluate():\n",
        "  \n",
        "  print(\"\\nEvaluating.....\")\n",
        "  \n",
        "  #set the model on training phase - Dropout layers are deactivated\n",
        "  model.eval()\n",
        "\n",
        "  #record the current time\n",
        "  t0 = time.time()\n",
        "\n",
        "  #initialize the loss and accuracy to 0\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  #Create a empty list to save the model predictions\n",
        "  total_preds = []\n",
        "\n",
        "  #for each batch  \n",
        "  for step,batch in enumerate(validation_dataloader):\n",
        "    \n",
        "    # Progress update every 40 batches.\n",
        "    if step % 40 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(validation_dataloader), elapsed))\n",
        "\n",
        "    #push the batch to gpu\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "\n",
        "    #unpack the batch into separate variables\n",
        "    # `batch` contains three pytorch tensors:\n",
        "    #   [0]: input ids \n",
        "    #   [1]: attention masks\n",
        "    #   [2]: labels        \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    #deactivates autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # Perform a forward pass. This returns the model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      #compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      # Accumulate the validation loss over all of the batches so that we can\n",
        "      # calculate the average loss at the end. `loss` is a Tensor containing a\n",
        "      # single value; the `.item()` function just returns the Python value \n",
        "      # from the tensor.      \n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      #The model predictions are stored on GPU. So, push it to CPU\n",
        "      preds=preds.detach().cpu().numpy()\n",
        "\n",
        "      #Accumulate the model predictions of each batch\n",
        "      total_preds.append(preds)\n",
        "\n",
        "  #compute the validation loss of a epoch\n",
        "  avg_loss = total_loss / len(validation_dataloader) \n",
        "\n",
        "  #The predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  #So, reshaping the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds"
      ],
      "metadata": {
        "id": "SoV18Cx4JS9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "5. Train the model\n"
      ],
      "metadata": {
        "id": "cOSVHUq3E2yU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assign the initial loss to infinite\n",
        "best_valid_loss=float('inf')\n",
        "\n",
        "# Create an empty list to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "epochs=5\n",
        "\n",
        "#for each epoch repeat call the train() method\n",
        "for epoch in range(epochs):\n",
        "  print('\\n ............epoch {:} / {:} .......'.format(epoch + 1, epochs))\n",
        "\n",
        "  #train model\n",
        "  train_loss,_ =train()\n",
        "\n",
        "  #evaluate model\n",
        "  valid_loss,_=evaluate()\n",
        "\n",
        "  # save the best model\n",
        "  if valid_loss<best_valid_loss:\n",
        "    best_valid_loss=valid_loss\n",
        "    torch.save(model.state_dict(),'Saved_weights.pt')\n",
        "\n",
        "  # Accumulate training and validaion loss\n",
        "  train_losses.append(train_loss)\n",
        "  valid_losses.append(valid_loss)\n",
        "\n",
        "  print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "  print(f'Validation Loss: {valid_loss:.3f}')\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "metadata": {
        "id": "QeLLAOsE0Gs5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "253d5212-064f-4bc6-8417-de3e6779d44b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ............epoch 1 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   563. Elapsed: 0:00:14.\n",
            " Batch   80 of   563. Elapsed: 0:00:29.\n",
            " Batch  120 of   563. Elapsed: 0:00:44.\n",
            " Batch  160 of   563. Elapsed: 0:00:59.\n",
            " Batch  200 of   563. Elapsed: 0:01:16.\n",
            " Batch  240 of   563. Elapsed: 0:01:32.\n",
            " Batch  280 of   563. Elapsed: 0:01:47.\n",
            " Batch  320 of   563. Elapsed: 0:02:02.\n",
            " Batch  360 of   563. Elapsed: 0:02:18.\n",
            " Batch  400 of   563. Elapsed: 0:02:34.\n",
            " Batch  440 of   563. Elapsed: 0:02:49.\n",
            " Batch  480 of   563. Elapsed: 0:03:05.\n",
            " Batch  520 of   563. Elapsed: 0:03:21.\n",
            " Batch  560 of   563. Elapsed: 0:03:36.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "\n",
            "Training Loss: 1.071\n",
            "Validation Loss: 0.979\n",
            "\n",
            " ............epoch 2 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   563. Elapsed: 0:00:16.\n",
            " Batch   80 of   563. Elapsed: 0:00:31.\n",
            " Batch  120 of   563. Elapsed: 0:00:47.\n",
            " Batch  160 of   563. Elapsed: 0:01:03.\n",
            " Batch  200 of   563. Elapsed: 0:01:18.\n",
            " Batch  240 of   563. Elapsed: 0:01:34.\n",
            " Batch  280 of   563. Elapsed: 0:01:50.\n",
            " Batch  320 of   563. Elapsed: 0:02:05.\n",
            " Batch  360 of   563. Elapsed: 0:02:21.\n",
            " Batch  400 of   563. Elapsed: 0:02:37.\n",
            " Batch  440 of   563. Elapsed: 0:02:52.\n",
            " Batch  480 of   563. Elapsed: 0:03:08.\n",
            " Batch  520 of   563. Elapsed: 0:03:23.\n",
            " Batch  560 of   563. Elapsed: 0:03:39.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "\n",
            "Training Loss: 0.985\n",
            "Validation Loss: 0.933\n",
            "\n",
            " ............epoch 3 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   563. Elapsed: 0:00:16.\n",
            " Batch   80 of   563. Elapsed: 0:00:31.\n",
            " Batch  120 of   563. Elapsed: 0:00:47.\n",
            " Batch  160 of   563. Elapsed: 0:01:03.\n",
            " Batch  200 of   563. Elapsed: 0:01:18.\n",
            " Batch  240 of   563. Elapsed: 0:01:34.\n",
            " Batch  280 of   563. Elapsed: 0:01:50.\n",
            " Batch  320 of   563. Elapsed: 0:02:05.\n",
            " Batch  360 of   563. Elapsed: 0:02:21.\n",
            " Batch  400 of   563. Elapsed: 0:02:36.\n",
            " Batch  440 of   563. Elapsed: 0:02:52.\n",
            " Batch  480 of   563. Elapsed: 0:03:08.\n",
            " Batch  520 of   563. Elapsed: 0:03:23.\n",
            " Batch  560 of   563. Elapsed: 0:03:39.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "\n",
            "Training Loss: 0.962\n",
            "Validation Loss: 0.898\n",
            "\n",
            " ............epoch 4 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   563. Elapsed: 0:00:16.\n",
            " Batch   80 of   563. Elapsed: 0:00:31.\n",
            " Batch  120 of   563. Elapsed: 0:00:47.\n",
            " Batch  160 of   563. Elapsed: 0:01:03.\n",
            " Batch  200 of   563. Elapsed: 0:01:18.\n",
            " Batch  240 of   563. Elapsed: 0:01:34.\n",
            " Batch  280 of   563. Elapsed: 0:01:49.\n",
            " Batch  320 of   563. Elapsed: 0:02:05.\n",
            " Batch  360 of   563. Elapsed: 0:02:21.\n",
            " Batch  400 of   563. Elapsed: 0:02:36.\n",
            " Batch  440 of   563. Elapsed: 0:02:52.\n",
            " Batch  480 of   563. Elapsed: 0:03:08.\n",
            " Batch  520 of   563. Elapsed: 0:03:23.\n",
            " Batch  560 of   563. Elapsed: 0:03:39.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "\n",
            "Training Loss: 0.939\n",
            "Validation Loss: 0.900\n",
            "\n",
            " ............epoch 5 / 5 .......\n",
            "\n",
            " Training\n",
            " Batch   40 of   563. Elapsed: 0:00:16.\n",
            " Batch   80 of   563. Elapsed: 0:00:31.\n",
            " Batch  120 of   563. Elapsed: 0:00:47.\n",
            " Batch  160 of   563. Elapsed: 0:01:02.\n",
            " Batch  200 of   563. Elapsed: 0:01:18.\n",
            " Batch  240 of   563. Elapsed: 0:01:33.\n",
            " Batch  280 of   563. Elapsed: 0:01:49.\n",
            " Batch  320 of   563. Elapsed: 0:02:04.\n",
            " Batch  360 of   563. Elapsed: 0:02:20.\n",
            " Batch  400 of   563. Elapsed: 0:02:36.\n",
            " Batch  440 of   563. Elapsed: 0:02:51.\n",
            " Batch  480 of   563. Elapsed: 0:03:07.\n",
            " Batch  520 of   563. Elapsed: 0:03:23.\n",
            " Batch  560 of   563. Elapsed: 0:03:38.\n",
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "\n",
            "Training Loss: 0.934\n",
            "Validation Loss: 0.882\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "6. Evaluate the model\n",
        "\n"
      ],
      "metadata": {
        "id": "6cvB38dE0tZj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load weights of best model\n",
        "path='Saved_weights.pt'\n",
        "model.load_state_dict(torch.load(path))"
      ],
      "metadata": {
        "id": "93OTP7dz0G72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36e2142a-00bb-495d-c29f-5ae655387bab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# get the model prediction on the validation data\n",
        "valid_loss,preds=evaluate()\n",
        "# this returns 2 elements- Validation loss and prediction\n",
        "print(valid_loss)"
      ],
      "metadata": {
        "id": "UlpvSgFD0oss",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6ebdee9-3b53-4a7e-afab-d702c6d01171"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating.....\n",
            "  Batch    40  of     63.    Elapsed: 0:00:15.\n",
            "0.8821669798048716\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Converting the log(probabilities) into class & then choosing index of maximum value as class\n",
        "y_pred=np.argmax(preds,axis=1)\n",
        "\n",
        "# actual labels\n",
        "y_true=validation_labels"
      ],
      "metadata": {
        "id": "xsj5m4XF0o_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_true,y_pred))"
      ],
      "metadata": {
        "id": "YbLTtyJ90pIB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "622a45f3-59b3-4359-8886-1494fbb9c022"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.40      0.72      0.51       250\n",
            "           1       0.90      0.81      0.85      1529\n",
            "           2       0.21      0.17      0.18       221\n",
            "\n",
            "    accuracy                           0.73      2000\n",
            "   macro avg       0.50      0.56      0.52      2000\n",
            "weighted avg       0.76      0.73      0.74      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ThWeW9Ko7XRN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "References\n",
        "\n",
        "- https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5\n",
        "\n",
        "- https://www.cs.toronto.edu/~lczhang/360/lec/w03/nn.html\n"
      ],
      "metadata": {
        "id": "G_KO56G37Xrb"
      }
    }
  ]
}